# Custom LLM Project (T5-base)

This project shows how to fine-tune a medium-sized T5 transformer using Hugging Face on a simple Q&A dataset.

## ğŸ“ Structure
- `sample_data.csv` â€“ CSV format training data
- `train.py` â€“ Training script using Hugging Face `Trainer`
- `Dockerfile` â€“ Build and run your model anywhere
- `requirements.txt` â€“ Python package dependencies

## ğŸš€ Train in Docker

```bash
docker build -t custom-llm .
docker run --rm custom-llm
